%===============================================================================
% COVID-19 Reproduction Numbers in South Africa
% Kevin Durant
% May 2020
%===============================================================================

\documentclass[12pt,a4paper]{article}

% \usepackage{booktabs} % better looking tables.
\usepackage{mathtools} % also loads amsmath.
\usepackage{microtype}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{amssymb}
\else
  % Unicode-math should be loaded after other maths- or font-related packages.
  % It loads amsmath and fontspec if necessary, and enables a custom version of
  % the Latin Modern Math font by default.
  \usepackage{unicode-math}
%   \setmainfont{STIX Two Text}
%   \setmathfont{STIX Two Math}
\fi
\usepackage{biblatex}
\usepackage{svg}
\usepackage{hyperref}
\addbibresource{cvza.bib}

% General maths commands %======================================================

\newcommand\ds{\displaystyle}                 % large maths.
\newcommand\ts{\textstyle}                    % small maths.
\newcommand\mb[1]{\mathbb{#1}}                % mathbb shorthand.
\newcommand\mc[1]{\mathcal{#1}}               % mathcal shorthand.
\newcommand\ub[1]{\symbf{#1}}                 % unicode-math symbf shorthand.
\newcommand\ff[1]{^{\underline{#1}}}          % falling factorial.
\newcommand\rf[1]{^{\overline{#1}}}           % rising factorial.
\newcommand\ul[1]{\underline{#1}}             % underline.
\newcommand\ol[1]{\overline{#1}}              % overline.
\DeclareMathOperator\Pb{P}                    % probability.
\DeclareMathOperator\Ex{E}                    % expected value.
\DeclareMathOperator\Va{V}                    % variance.
\DeclarePairedDelimiter\lr{\lparen}{\rparen}  % sized parentheses.
\DeclarePairedDelimiter\lrb{\lbrack}{\rbrack} % sized brackets.
\DeclarePairedDelimiter\abs{\lvert}{\rvert}   % absolute value symbol.
\DeclarePairedDelimiter\cl{\lceil}{\rceil}    % ceiling symbol.
\DeclarePairedDelimiter\fl{\lfloor}{\rfloor}  % floor symbol.
\DeclareMathOperator\B{B}                     % beta distribution.
\DeclareMathOperator\BP{BP}                   % beta prime distribution.
\DeclareMathOperator\NB{NB}                   % negative binomial distribution.

% Title %=======================================================================

\title{Estimating COVID-19 Reproduction Numbers}
\author{Kevin Durant}
\date{June 2020}

% Document %====================================================================

\begin{document}

\maketitle

\begin{abstract}
This is a short description of an analytic, \emph{almost} fully Bayesian
solution to the problem of inferring effective reproduction numbers for an
epidemic from reported infection counts. Under the assumptions of a negative
binomial likelihood function and a simple beta prime distributed predictive
prior, the posterior distribution of the daily infection rate follows a beta
prime distribution whose parameters can be expressed in closed form. These
posteriors can in turn be used to estimate effective reproduction numbers.
\end{abstract}

\section{Introduction} %========================================================

The effective reproduction number of an epidemic, $R_t$, refers to the expected
number of new infections caused by a single infected individual at a given stage
of the epidemic's course. Along with other, complementary measures, these
numbers can help give an indication of the rate at which the epidemic is
spreading.

The method for estimating effective reproduction numbers discussed here is a
slightly different take on one described elsewhere by Kevin
Systrom~\cite{systrom2020}, which is itself based on work
by~\citeauthor{bettencourt2008}~\cite{bettencourt2008}. Unlike those two
approaches, the solution described here is almost entirely analytic---the only
numerical computation required being that of percentiles of a beta prime
distribution. All three methods are based on a key point made by the latter
authors mentioned above: that under the assumptions of a standard epidemic
susceptible-infected~(SIR) model, the effective reproduction number of a virus
at time~$t$ can be estimated from the number of new cases recorded between
times~$t-1$ and~$t$, and~$t$ and~$t+1$.

More specifically, let~$R_t$ be the effective reproduction number at time~$t$,
and assume that this number remains constant over the interval~$(t-1, t]$ (most
likely a single day)\footnote{Note that our notation differs slightly from that
used by~\citeauthor{bettencourt2008}---our~$R_t$ and~$\lambda_t$ correspond to
their~$R_{t-1}$ and~$\Delta T(t)$ respectively.}. Likewise, let~$\lambda_t$ be
the average number of new infections that occur during this interval---i.e., the
current rate of infection. One then has the following
approximation~\cite{bettencourt2008}:
\begin{equation*}
  \lambda_t \approx \lambda_{t-1}\exp(\gamma(R_t - 1)),
\end{equation*}
in which $\gamma$ is the reciprocal of the infectious period of the virus.
Equivalently,
\begin{equation}\label{eqn:R_t}
  R_t \approx \frac{1}{\gamma} \log\lr*{\frac{\lambda_t}{\lambda_{t-1}}} + 1.
\end{equation}

The approach outlined here involves modelling the number of observed
infections~$k_t$ as a stochastic process, assuming that $k_t$ depends on an
underlying rate of infection~$\lambda_t$ via a negative binomial distribution (a
Poisson distribution can also be used). One can then infer the infection
rates~$\lambda_t$ analytically, and use them to estimate effective reproduction
numbers by applying equation~\eqref{eqn:R_t}.

Specifically, one finds that the posterior rate of infection~$\lambda_t$ can be
described using a beta prime distribution:
\begin{equation*}
  \Pb\lr*{\frac{\lambda_t}{r} \Bigm\vert k_1, \dots, k_{t-1}}
  = \BP\lr*{\frac{\lambda_t}{r} \Bigm\vert \alpha_t, \beta_t},
\end{equation*}
in which
\begin{align}\label{eqn:recursion}
\begin{split}    
    \alpha_t &= \frac{a_1}{c^{t-1}} + \sum_{i=0}^{t-1} \frac{k_{t-i}}{c^i}, \\
    \beta_t &= \frac{b_1}{c^{t-1}} + \sum_{i=0}^{t-1} \frac{r}{c^i}
    = \frac{b_1}{c^{t-1}} + r\frac{1 - \frac{1}{c^t}}{1 - \frac{1}{c}}.
\end{split}
\end{align}
Both $r$ and $c$ are model parameters that can easily be optimised, because
their marginal likelihood~$\Pb(k_1, \dots, k_{t-1} \mid r, c)$ is available in
closed form. The constants $a_1$ and~$b_1$ are parameters of the initial prior
on $\lambda_1$.

We apply this model to the estimation of reproduction numbers in
section~\ref{sec:application}, by making use of a simplified version of
equation~\eqref{eqn:R_t} in which $\lambda_{t-1}$ is replaced with a point
estimate~$\lambda_{t-1}^*$. We use, for example, the median value of
$\Pb(\lambda_{t-1} \mid k_1, \dots, k_{t-2})$ as such an estimate.

\section{The stochastic process} %==============================================

Let~$\ub{k} = k_1, \dots, k_{t-1}$ be a sequence of observed infection counts,
and~$\ub{\lambda}$ the corresponding sequence of unknown infection rates. The
primary assumption is that each~$k$ and~$\lambda$ are related via a negative
binomial distribution:
\begin{equation}\label{eqn:likelihood}
  \Pb(k_t \mid \lambda_t, \ub{k}) = \Pb(k_t \mid \lambda_t)
  \sim \NB\lr*{k_t \Bigm\vert r, \frac{\lambda_t}{r + \lambda_t} = p_t},
\end{equation}
where $r$ is an unknown dispersion parameter and $p_t$ is a reparameterisation
of $\lambda_t$ as a `success' probability. Parameterised in this way, the
negative binomial distribution converges to a Poisson distribution of
rate~$\lambda_t$ as~$r \to \infty$, and by adjusting $r$ we can control the
level of variance inherent to the distribution (smaller values of $r$ result in
higher variance).

Inference of the rate sequence~$\ub{\lambda}$ is performed iteratively, by
repeated application of Bayes' rule:
\begin{equation*}
  \Pb(\lambda_t \mid k_t, \ub{k}) \propto \Pb(k_t \mid \lambda_t)
    \Pb(\lambda_t \mid \ub{k}).
\end{equation*}
The first term on the right-hand side---the likelihood function---is simply the
negative binomial distribution given above. The second term is a predictive
prior on~$\lambda_t$ given only the \emph{past} infection counts~$\ub{k}$.
Technically the inference will be done with respect to $\ub{p} = p_1, \dots,
p_{t-1}$, not $\ub{\lambda}$, but with the right choice of prior the translation
between the two is seamless.

The conjugate prior for the negative binomial likelihood function (with known
dispersion) is the beta distribution, so our second assumption is that the prior
distribution on $p_t$ is of this form. Note that the change-of-variable formula
for probability density functions implies that when $p_t$ follows a beta
distribution, $\lambda_t/r$ is distributed according to a beta prime
distribution with identical parameters:
\begin{equation*}
  p_t \sim \B(p_t \mid \alpha, \beta)
  \Rightarrow \frac{\lambda_t}{r}
    \sim \BP\lr*{\frac{\lambda_t}{r} \Bigm\vert \alpha, \beta}.
\end{equation*}
As mentioned above, this allows us to work with $p_t$ instead of $\lambda_t$
while deriving posteriors and marginal likelihoods, but still consider
$\lambda_t$ when computing $R_t$.

The third and final assumption we make involves the way in which the predictive
prior $\Pb(p_t \mid \ub{k})$ is derived from the previous posterior $\Pb(p_{t-1}
\mid \ub{k})$. In the case of a Gaussian stochastic process, one would derive
the prior by assuming additive Gaussian noise on the previous latent variable,
resulting in a distribution that has the same mean as the previous posterior,
but higher variance. Doing so involves solving an integral of the form
\begin{equation*}
  \Pb(p_t \mid \ub{k}) = \int \Pb(p_t \mid p_{t-1})
    \Pb(p_{t-1} \mid \ub{k})\, dp_{t-1},
\end{equation*}
which is tractable in the Gaussian case.

Although the situation is not quite as straightforward here, we can achieve a
similar outcome by simply assuming the relationship to the previous posterior
directly: specifically, if
\begin{equation}\label{eqn:posterior form}
  \Pb(p_{t-1} \mid \ub{k}) \sim \B(p_{t-1} \mid \alpha_{t-1}, \beta_{t-1}),
\end{equation}
we might assume a predictive prior of the form
\begin{equation}\label{eqn:prior}
  \Pb(p_t \mid \ub{k}) \sim \B(p_t \mid \alpha_{t-1}/c, \beta_{t-1}/c)
  = \B\lr*{p_t \mid a_t, b_t}.
\end{equation}
This is a straightforward prior that has the same mean as the predictive
posterior on~$p_{t-1}$, but a variance that is larger \emph{roughly} by a
factor~$c$---since the mean and variance of a beta distribution with parameters
$\alpha$ and $\beta$ are given by
\begin{equation*}
  \Ex[X] = \frac{\alpha}{\alpha + \beta}, \quad
  \Va[X] = \frac{\alpha\beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)},
\end{equation*}
and in general $c$ will be small relative to $\alpha + \beta$.

One could just as easily make use of a predictive prior that introduces additive
noise, unlike the multiplicative noise described above. The main reason for
choosing multiplicative noise here is that changes in scale made to~$p_t$ (and
$\lambda_t$) result in additive changes to~$R_t$, so in this way one is
effectively introducing additive noise into the overarching reproduction number
process.

The remaining details of the stochastic process now follow from
assumptions~\eqref{eqn:likelihood} and~\eqref{eqn:prior}. Firstly--and most
importantly---the posterior on~$p_t$ is given by
\begin{align*}
  \Pb(p_t \mid k_t, \ub{k}) &\propto \Pb(k_t \mid p_t) \Pb(p_t \mid \ub{k}) \\
  &= \NB(k_t \mid r, p_t)\, \B(p_t \mid a_t, b_t) \\
  &\sim p_t^{k_t} (1 - p_t)^r \cdot p_t^{a_t-1} (1 - p_t)^{b_t-1} \\
  &\Rightarrow \B(p_t \mid a_t + k_t, b_t + r).
\end{align*}
That is (extending equation~\eqref{eqn:posterior form}):
\begin{equation}\label{eqn:posterior}
  \Pb(p_t \mid k_t, \ub{k}) \sim \B(p_t \mid a_t + k_t, b_t + r)
  = \B(p_t \mid \alpha_t, \beta_t).
\end{equation}
Combining this with equation~\eqref{eqn:prior} one can solve for $\alpha_t$
and~$\beta_t$ recursively, leading to equation~\eqref{eqn:recursion}. Note
however that these solutions presume that the time series of data points is
complete; in the presence of a missing datum $k_t$ one will need to specify
$\alpha_t$ and~$\beta_t$ explicitly---for example simply by setting them to
$a_t$ and~$b_t$ respectively.

Secondly, we can derive the marginal likelihood of observation~$k_t$ given the
previous observations:
\begin{align}\label{eqn:marginal}
  \Pb(k_t \mid \ub{k}) &= \int \Pb(k_t, p_t \mid \ub{k})\, dp_t \nonumber \\
  &= \int \NB(k_t \mid r, p_t)\, \B(p_t \mid a_t, b_t)\, dp_t \nonumber \\
  &= \binom{k_t + r - 1}{k_t} \frac{1}{\Beta(a_t, b_t)}
    \int p_t^{a_t+k_t-1} (1 - p_t)^{b_t+r-1}\, dp_t \nonumber \\
  &= \begin{dcases}
    \frac{\Beta(a_t, b_t + r)}{\Beta(a_t, b_t)} &\text{if } k_t = 0, \\
    \frac{1}{k_t\Beta(k_t, r)}\frac{\Beta(a_t + k_t, b_t + r)}{\Beta(a_t, b_t)}
      &\text{if } k_t > 0,
  \end{dcases}
\end{align}
where~$\Beta(x, y)$ denotes the beta function. (The final expression can also be
rephrased in terms of $\alpha_t$ and $\beta_t$ using
equation~\eqref{eqn:posterior}.) This allows us to compute the overall marginal
likelihood iteratively, since
\begin{equation*}
  \Pb(\ub{k}) = \prod_{i=1}^{t-1} \Pb(k_i \mid k_1, \dots, k_{i-1}).
\end{equation*}
The overall marginal likelihood will in turn allow us to compare the relative
likelihoods of values of~$r$ and~$c$, which are the model's two tunable
parameters.

Equations~\eqref{eqn:prior} and~\eqref{eqn:posterior} allow us to derive,
via~$p_t$, a posterior distribution for each~$\lambda_t$. Ideally one would hope
for a distribution on~$\lambda_t/\lambda_{t-1}$, since this is the ratio on
which~$R_t$ depends (equation~\eqref{eqn:R_t}), however this would require one
to either specify~$\Pb(p_t \mid p_{t-1})$---something we explicitly avoiding
doing above to keep things tractable---or treat $\lambda_t$ and~$\lambda_{t-1}$
as independent for the purposes of deriving $R_t$.

Here we adopt a simpler approach: replace $\lambda_{t-1}$ in
equation~\eqref{eqn:R_t} with a point estimate~$\lambda_{t-1}^*$, resulting in
the approximation
\begin{equation}\label{eqn:R_t approximation}
  R_t \approx \frac{1}{\gamma} \log\lr*{\frac{\lambda_t}{\lambda_{t-1}}} + 1
    \approx \frac{1}{\gamma}
    \log\lr*{\frac{\lambda_t}{r}\frac{r}{\lambda_{t-1}^*}} + 1,
\end{equation}
to which our inferred posterior on $\lambda_t/r$ can directly be applied. This
is not unlike a simplification made by the other
authors~\cite{bettencourt2008,systrom2020}, who set~$\lambda_{t-1}^* = k_{t-1}$.
In what follows, we have set $\lambda_{t-1}^*$ to the median of the posterior
distribution~$\Pb(\lambda_{t-1} \mid k_1, \dots k_{t-1})$ (which is simply $r$
times the median of the posterior on $\lambda_{t-1}/r$).

Before moving on, we note that~\citeauthor{bettencourt2008} also describe a
negative binomial process in which $r$ is not constant, but rather $r_t =
k_{t-1}$. We have briefly tested this approach, and in practice it performs
similarly to the one we have described above; the main difference being that the
precision of the likelihood function (and thus posterior) varies with the
observed counts~$\ub{k}$. The approach outlined in this section can still be
applied, and the resulting analytic solution differs only slightly.

\subsection*{An application to South African data}\label{sec:application} %=====

In this section we apply the steps described above to data stemming from the
COVID-19 epidemic in South Africa. The data set used here is obtained from South
Africa's National Institute for Communicable Diseases, via the University of
Pretoria~\cite{dsfsi2020}. The data take the form of daily cumulative infection
counts per province, from which we derive new infection counts per day.

\begin{figure}[htb]
  \centering
  \includeinkscape{img/counts}
  \caption{Daily new infection counts for the COVID-19 epidemic in South Africa,
    smoothed using a Gaussian window with a standard deviation of~$\sigma =
    3.5$. Shaded areas indicate different levels of the nationwide lockdown,
    with the first, grey area depicting the period between the announcement of
    the lockdown and its initiation.}
  \label{fig:counts}
\end{figure}

Before inferring daily infection rates, we first need to decide whether or not
the raw counts should be smoothed, and if so, to what extent (see
figure~\ref{fig:counts}). The obvious argument against doing so is that the
variance of $R_t$ depends indirectly on the variance of the $k_t$, so smoothed
infection counts may result in artificially precise posteriors.

On the other hand, one might argue that the underlying assumption of the model
is that $k_t$ represents the \emph{true} number of infections on a given day, of
which smoothed counts are likely a more appropriate indication. A second, more
technical argument for reducing the variance of the reported infection counts is
the fact that the equation $\lambda_t \approx \lambda_{t-1}\exp(\gamma(R_t -
1))$ contains an implicit assumption: that $R_t \ge 0$, and thus
$\lambda_t/\lambda_{t-1} \ge \exp(-\gamma)$.

\begin{figure}[htb]
  \centering
  \includeinkscape{img/ratio}
  \caption{Ratios of consecutive infection counts~$k_t/k_{t-1}$ for various
    levels of Gaussian smoothing. The red line indicates the bound implied by
    equation~\eqref{eqn:R_t}.}
  \label{fig:ratio}
\end{figure}

In figure~\ref{fig:ratio} we plot the ratio~$k_t/k_{t-1}$ for various levels of
Gaussian averaging---roughly corresponding to smoothing windows of 0.5, 1, and~2
weeks (if one uses four standard deviations as a guide). One sees that in this
case, windows with scales greater than $\sigma = 7/3$ appear both to respect the
implicit bound mentioned above, as well as alleviate much of the periodicity
visible in the raw count sequence.

For the remainder of this example we will counts that have been averaged using a
Gaussian window with standard deviation~$\sigma = 3.5$. This value will not
necessarily be suitable for data sets from other regions or sources, however.

The rest of the application is straightforward: we apply
equation~\eqref{eqn:marginal} to select values for $r$ and~$c$ that maximise the
marginal likelihood (for the countrywide South African data this yields $r =
1592$ and~$c \approx 3.56$), and then use equation~\ref{eqn:posterior} to
compute the parameters of the posteriors on $\lambda_1, \lambda_2, \dots$. These
posteriors, shown in figure~\ref{fig:posterior}, track the smoothed $k_t$
relatively closely, as one might expect.

Finally, equation~\eqref{eqn:R_t approximation} allows us to plot the estimated
evolution of $R_t$ over time, simply by mapping percentiles of $\lambda_t/r$ to
those of~$R-t$. This plot is shown in figure~\ref{fig:countrywide} for the
entire country, and figure~\ref{fig:provincial} on a provincial level.

\begin{figure}[htbp]
  \centering
  \includeinkscape{img/posterior}
  \caption{Daily posterior infection rates~$\lambda_t$, plotted as a median and
    5--95th percentile interval.}
  \label{fig:posterior}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includeinkscape{img/countrywide}
  \caption{Estimated reproduction numbers~$R_t$ for the COVID-19 epidemic in
    South Africa, plotted as a median and 5--95th percentile interval.}
  \label{fig:countrywide}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includeinkscape{img/provincial}
  \caption{Reproduction numbers for the COVID-19 epidemic in South Africa,
    estimated at a provincial level.}
  \label{fig:provincial}
\end{figure}

The only comment we will make on these figures is that the effect of the hard
lockdown (implemented on 28 March) on the estimated reproduction numbers is
clearly visible, as is---to a lesser extent---the slow relaxation of lockdown
restrictions and gradual reopening of economic activity that follows.

% Bibliography %================================================================

\printbibliography

\end{document}